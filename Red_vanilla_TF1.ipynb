{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia de Red_vanilla_TF1X (1) (1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yslen7/NeuralNetworks/blob/main/Red_vanilla_TF1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPitwRrcRpma"
      },
      "source": [
        "### Importación de Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7DwA6QEYIds",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06241130-f7c6-4358-efc6-20c62e236ab6"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPZtMACjRpmc"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LvwzIXaRpmf"
      },
      "source": [
        "### Importación de datos "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4B4h-7glRpmg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfc42a6a-64e4-41bd-ac1a-98fa69d5cfd9"
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"input/data/\", one_hot = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-ce8afb69b99e>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting input/data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting input/data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Extracting input/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting input/data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wi_nqCWxRpmo"
      },
      "source": [
        "### verificando los datos de prueba"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcqBlhxhRpmo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ace7dfa-55aa-4f8c-d25a-90f4b95330e1"
      },
      "source": [
        "mnist.train.images.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LW4wwLYRpmr"
      },
      "source": [
        "imagendemo=np.reshape(mnist.train.images[24,:],(28,28))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uOJRGzQRpmu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "2328e230-a67c-470e-8a0a-27202f9b6b8e"
      },
      "source": [
        "plt.imshow(imagendemo,cmap='gray')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f3900fed438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScIUfHpaQQyJ"
      },
      "source": [
        "def image_matrix(img):\n",
        "    print('\\n'.join([''.join(['{:4}'.format(int(round(item*255))) for item in row]) \n",
        "      for row in img]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6AK5fDJQQyM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deaacec3-f883-4f50-a2d8-cf9d8b0f6375"
      },
      "source": [
        "image_matrix(imagendemo)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0 108 254 215 196   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0 121 252 194 199 238 152  24   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0 209 226  31   0 182 254 109   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0  72 254  89   0   0 136 254 109   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0 156 254  18   0   0   0 254 173   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   6 203 182   0   0   0   0 197 200   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0  19 254  78   0   0   0   0 183 199   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0  97 254  46   0   0   0  92 254 141 160  92   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0  38 254 220 148 110 110 213 254 254 254 144   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   6 169 255 254 254 254 254 196 163 208 210   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0  85  92  92  59   0   0 128 248  47   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 128 254 125   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 128 254 163   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 121 254 163   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  37 254 163   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 201 189   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 200 254  20   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 123 254 105   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  71 254 187   2   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   6 169 254  83   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUPvkJ1URpmy"
      },
      "source": [
        "### Declarando la arquitectura\n",
        "\n",
        "Generando función "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0n-_0mxcRpmz"
      },
      "source": [
        "def Neural_network_model(\n",
        "    n_nodes_hl1=500,\n",
        "    n_nodes_hl2=500,\n",
        "    n_nodes_hl3=500,\n",
        "    n_classes=10\n",
        "    ):\n",
        "    # Declarando las entradas y salidas\n",
        "    #Placeholder para guardar el espacio, cambia cada que hacemos un run\n",
        "    #Verifica que la entrada es correcta según el tipo de variable (float,int)\n",
        "    #No sabemos cuántos propagar de golpe (None), tamaño de 784. Badge y mini badge\n",
        "    x=tf.placeholder('float',[None,784])\n",
        "    y=tf.placeholder('float')\n",
        "    \n",
        "    # Declarando las variables \n",
        "    #Variable: todo lo que puede ser modificado por el gradiente. Pesos, bias\n",
        "    \n",
        "    hidden_1_layer = {'weights':tf.Variable(tf.random_normal([784, n_nodes_hl1])),\n",
        "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl1]))}\n",
        "\n",
        "    hidden_2_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_hl2])),\n",
        "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl2]))}\n",
        "\n",
        "    hidden_3_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl2, n_nodes_hl3])),\n",
        "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl3]))}\n",
        "\n",
        "    output_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl3, n_classes])),\n",
        "                    'biases':tf.Variable(tf.random_normal([n_classes]))}\n",
        "    \n",
        "    \n",
        "    # Declarando la arquitectura\n",
        "    #matmul=a*b, más eficiente que una simple multiplicación\n",
        "    l1 = tf.add(tf.matmul(x,hidden_1_layer['weights']), hidden_1_layer['biases'])\n",
        "    l1 = tf.nn.relu(l1)\n",
        "\n",
        "    l2 = tf.add(tf.matmul(l1,hidden_2_layer['weights']), hidden_2_layer['biases'])\n",
        "    l2 = tf.nn.relu(l2)\n",
        "\n",
        "    l3 = tf.add(tf.matmul(l2,hidden_3_layer['weights']), hidden_3_layer['biases'])\n",
        "    l3 = tf.nn.relu(l3)\n",
        "\n",
        "    output = tf.matmul(l3,output_layer['weights']) + output_layer['biases']\n",
        "    \n",
        "    # Declarando la funcion de costo y optimizador\n",
        "    #Métrica.... veremos por qué usar esa\n",
        "    #Media de todos esos valores, error promedio\n",
        "    cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(logits=output\n",
        "                                                                   , labels=y) )\n",
        "    #Algortimo de optimización... escojemos uno de la gama de algoritmos de TF\n",
        "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
        "    \n",
        "    return dict(\n",
        "              x=x,\n",
        "              y=y,\n",
        "              output=output,\n",
        "              cost=cost,\n",
        "              optimizer=optimizer\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SB_ocuTDRpm2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee7d581d-d9c7-4d90-c2d9-a71b51eec4d9"
      },
      "source": [
        "#Prueba del modelo\n",
        "#Solo declaramos la arquitectura, pero no está haciendo nada. Python es lenguaje interpretado, así que debemos de dar info, corre línea por línea\n",
        "#En Cuda es todo compilado. \n",
        "Neural_network_model()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-9-c21fba062052>:47: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cost': <tf.Tensor 'Mean:0' shape=() dtype=float32>,\n",
              " 'optimizer': <tf.Operation 'Adam' type=NoOp>,\n",
              " 'output': <tf.Tensor 'add_3:0' shape=(?, 10) dtype=float32>,\n",
              " 'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>,\n",
              " 'y': <tf.Tensor 'Placeholder_1:0' shape=<unknown> dtype=float32>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnND6eokQQyb"
      },
      "source": [
        "## función de entrenamiento  y prueba"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-cDNuusRpm8"
      },
      "source": [
        "#Aquí controlamos el modelo (DNN), núm de epochs y tamaño del batch, que tiene que ver con el núm de datos que propago de golpe\n",
        "def train_neural_network(DNN, hm_epochs=10,batch_size=100):\n",
        "  #Todo dentro de tf.Session es lo que envia a Cuda una vez ejecutado. En TF1 no se hacen cálculos que no estén dentro de una sesión\n",
        "    with tf.Session() as sess:\n",
        "      #Inicializa todas las varibales y ejecútalas. Lo de la otra función hasta aquí se ejecutan (antes no)\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "\n",
        "        for epoch in range(hm_epochs):\n",
        "            epoch_loss = 0\n",
        "            #Iteración dependiente del número de datos y tamaño del batch (en este caso son 550 por 5500/100)\n",
        "            for _ in range(int(mnist.train.num_examples/batch_size)):\n",
        "                epoch_x, epoch_y = mnist.train.next_batch(batch_size)\n",
        "                #Diccionario de alimentación\n",
        "                feed_dict={DNN[\"x\"]: epoch_x, \n",
        "                           DNN[\"y\"]: epoch_y}\n",
        "                _, c, prediction,y   = sess.run([DNN[\"optimizer\"], DNN[\"cost\"]\n",
        "                                                 , DNN[\"output\"], DNN[\"y\"]], \n",
        "                                                feed_dict=feed_dict)\n",
        "                epoch_loss += c\n",
        "\n",
        "            print('Epoch', epoch, 'completed out of',hm_epochs,'loss:',epoch_loss)\n",
        "        \n",
        "        ## prueba con el conjunto de entrenamiento \n",
        "        #Pr=[]\n",
        "        #Lb=[]\n",
        "        #for _ in range(int(mnist.train.num_examples/batch_size)):\n",
        "        #        epoch_x, epoch_y = mnist.train.next_batch(batch_size)\n",
        "        #        feed_dict={DNN[\"x\"]: epoch_x, \n",
        "        #                   DNN[\"y\"]: epoch_y}\n",
        "        #        prediction,y   = sess.run([DNN[\"output\"], DNN[\"y\"]], \n",
        "        #                                        feed_dict=feed_dict)\n",
        "        #        Pr.extend(prediction)\n",
        "        #        Lb.extend(y)\n",
        "        #correct = tf.equal(tf.argmax(Pr, 1), tf.argmax(Lb, 1))\n",
        "        #accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
        "        #print('Accuracy:',accuracy.eval())\n",
        "        \n",
        "        #Prueba con datos nunca antes vistos  \n",
        "        #Propagación hacia adelante de los datos\n",
        "        prediction,y   = sess.run([DNN[\"output\"], DNN[\"y\"]], feed_dict={DNN[\"x\"]:mnist.test.images, DNN[\"y\"]:mnist.test.labels})\n",
        "        correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
        "        print('Accuracy:',accuracy.eval())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFKfo19DRpnB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c0f5a64-f3db-4b56-bf50-6d4dda0e136c"
      },
      "source": [
        "DNN=Neural_network_model()\n",
        "train_neural_network(DNN)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 completed out of 10 loss: 1898614.4506835938\n",
            "Epoch 1 completed out of 10 loss: 405487.3246216774\n",
            "Epoch 2 completed out of 10 loss: 224142.21377325058\n",
            "Epoch 3 completed out of 10 loss: 131077.11242866516\n",
            "Epoch 4 completed out of 10 loss: 77576.20917785168\n",
            "Epoch 5 completed out of 10 loss: 50410.996159037575\n",
            "Epoch 6 completed out of 10 loss: 30844.709698002112\n",
            "Epoch 7 completed out of 10 loss: 22366.653508827432\n",
            "Epoch 8 completed out of 10 loss: 17681.64629998803\n",
            "Epoch 9 completed out of 10 loss: 16355.38139387548\n",
            "Accuracy: 0.9527\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}