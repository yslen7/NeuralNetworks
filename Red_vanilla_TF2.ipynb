{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia de Red_vanilla_TF2 (3).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPitwRrcRpma"
      },
      "source": [
        "### Importación de Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7DwA6QEYIds"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPZtMACjRpmc"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LvwzIXaRpmf"
      },
      "source": [
        "### Importación de datos |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4B4h-7glRpmg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da08545d-151d-4efa-c49c-0dcb1c867b95"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data( )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wi_nqCWxRpmo"
      },
      "source": [
        "### verificando los datos de prueba"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGtfUZ4me432",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ccb256a-5fa3-45ae-b5c9-676bfff5a685"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcqBlhxhRpmo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07e04c3f-5c0b-43e8-e82a-2bf0e5b5d0d0"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uOJRGzQRpmu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "c2a7521b-4349-47e4-943f-cafa809db91e"
      },
      "source": [
        "imagendemo=x_train[24]\n",
        "plt.imshow(imagendemo,cmap='gray')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fe9845646d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAANBElEQVR4nO3dX6hd9ZnG8ecZTS6SlJCoPQYTJrXGi1DUSvAPI4NDaXG8ibnRJFAyTvB4odhCL6qdiwrjgISJIgiFE4zNDDW1osYQZFonhDqjEDwG/yRq61GjTTzJUQPGoJho3rk4K8Opnv3bx7332msn7/cDh733es/a63WRx7X2+u2zfo4IATjz/U3TDQDoD8IOJEHYgSQIO5AEYQeSOLufG7PNpX+gZhHh6ZZ3dWS3fZ3tP9kes31nN+8FoF7udJzd9lmS/izph5IOSHpB0pqIeK2wDkd2oGZ1HNmvkDQWEW9HxHFJv5W0sov3A1CjbsJ+gaS/THl9oFr2V2wP2x61PdrFtgB0qfYLdBExImlE4jQeaFI3R/aDkpZMeb24WgZgAHUT9hckLbP9HduzJa2WtL03bQHotY5P4yPiC9u3S/q9pLMkbY6IfT3rDEBPdTz01tHG+MwO1K6WL9UAOH0QdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQRF9vJY0zz9atW4v1q666qmVt9erVxXV3797dUU+YHkd2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCu8uiK88//3yxfvXVV7esjY2NFdddvnx5sX7ixIliPSvuLgskR9iBJAg7kARhB5Ig7EAShB1IgrADSTDOjqIlS5YU62+99VaxPmvWrI63PWfOnGL9s88+6/i9z2Stxtm7unmF7f2SPpH0paQvImJFN+8HoD69uFPNP0TEhz14HwA14jM7kES3YQ9Jf7D9ou3h6X7B9rDtUdujXW4LQBe6PY2/JiIO2v62pGdsvxERz079hYgYkTQicYEOaFJXR/aIOFg9Tkh6UtIVvWgKQO91HHbbc21/69RzST+StLdXjQHorW5O44ckPWn71Ps8EhH/1ZOuMDDmz59frHczjr5t27Zi/fPPP+/4vfF1HYc9It6WdGkPewFQI4begCQIO5AEYQeSIOxAEoQdSIIpm5M7++zyP4G77rqrtm0/8sgjxfrJkydr23ZGHNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnG2ZO7//77i/W1a9f2qRPUjSM7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBOPsZ7pZbbinW169f36dO0DSO7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBOPsZ4Cbb765Ze3BBx8srjt79uxifc+ePcX65ZdfXqxjcLQ9stvebHvC9t4pyxbafsb2m9XjgnrbBNCtmZzG/1rSdV9ZdqeknRGxTNLO6jWAAdY27BHxrKQjX1m8UtKW6vkWSTf0uC8APdbpZ/ahiBivnh+SNNTqF20PSxrucDsAeqTrC3QREbajUB+RNCJJpd8DUK9Oh94O214kSdXjRO9aAlCHTsO+XdK66vk6SU/1ph0AdWl7Gm97q6RrJZ1r+4CkX0q6V9LvbK+X9K6kG+tschDMmzevZe3SSy8trnvxxRcX61deeWWxfuON5d27YEHnI5933HFHsf70008X62NjYx1vG/3VNuwRsaZF6Qc97gVAjfi6LJAEYQeSIOxAEoQdSIKwA0nwJ64ztHjx4pa1zZs3F9dtN/TWzscff1ysb9q0qWVtw4YNxXX3799frJf+u3F64cgOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kwzj5Db7zxRsvaJZdcUlx32bJlXW376NGjxfp7773X1fs3Ze7cuU23kApHdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IwhH9m6SFGWFOP+ecc06xvnfv3mL9/PPPb1nbtm1bcd1Vq1YV65heRHi65RzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJ/p4dRR999FGx/s477xTrpXH2Xbt2ddQTOtP2yG57s+0J23unLLvb9kHbL1U/19fbJoBuzeQ0/teSrptm+f0RcVn183Rv2wLQa23DHhHPSjrSh14A1KibC3S3236lOs1f0OqXbA/bHrU92sW2AHSp07D/StJ3JV0maVzSxla/GBEjEbEiIlZ0uC0APdBR2CPicER8GREnJW2SdEVv2wLQax2F3faiKS9XSSr/nSOAxrUdZ7e9VdK1ks61fUDSLyVda/sySSFpv6Rba+wRZ6jx8fGmW0ilbdgjYs00ix+qoRcANeLrskAShB1IgrADSRB2IAnCDiTBn7iiVqVblU9MTPSxE3BkB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkGGc/DVx00UXF+sKFCzt+708//bRYP3KkfPvB++67r1jfsGFDy9p5551XXLddfc6cOcX6Pffc07L22GOPFdfdvn17sX464sgOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kwzt4Ds2fPLtYvvPDCYn14eLhYv/XW8p262403lxw/frxYP3bsWLHezRh/u7HuDz74oFhvt9/nz5/fsnbo0KHiuoyzAzhtEXYgCcIOJEHYgSQIO5AEYQeSIOxAEoyzz9DQ0FDL2gMPPFBc96abbup1OzPWblrk0n3dJWnfvn3F+ssvv/yNexoEW7ZsabqFvmt7ZLe9xPYu26/Z3mf7J9Xyhbafsf1m9big/nYBdGomp/FfSPpZRCyXdJWk22wvl3SnpJ0RsUzSzuo1gAHVNuwRMR4Re6rnn0h6XdIFklZKOnUutEXSDXU1CaB73+gzu+2lkr4vabekoYg49YHwkKRpP9TaHpZU/vI3gNrN+Gq87XmSHpf004g4OrUWk1d5pr3SExEjEbEiIlZ01SmArswo7LZnaTLov4mIJ6rFh20vquqLJDElJzDA2p7G27akhyS9HhFT7xu8XdI6SfdWj0/V0uGAWLt2bcta3UNrO3bsKNY3btzYsvbcc88V1z1x4kRHPeH0M5PP7H8n6ceSXrX9UrXsF5oM+e9sr5f0rqQb62kRQC+0DXtE/K8ktyj/oLftAKgLX5cFkiDsQBKEHUiCsANJEHYgCbf7E8eebszu38Z6bOnSpS1r7W47/P777xfrjz76aLH+8MMPF+vAVBEx7egZR3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJxduAMwzg7kBxhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJNE27LaX2N5l+zXb+2z/pFp+t+2Dtl+qfq6vv10AnWp78wrbiyQtiog9tr8l6UVJN2hyPvZjEfHvM94YN68Aatfq5hUzmZ99XNJ49fwT269LuqC37QGo2zf6zG57qaTvS9pdLbrd9iu2N9te0GKdYdujtke76hRAV2Z8Dzrb8yT9UdK/RcQTtockfSgpJP2rJk/1/7nNe3AaD9Ss1Wn8jMJue5akHZJ+HxH3TVNfKmlHRHyvzfsQdqBmHd9w0rYlPSTp9alBry7cnbJK0t5umwRQn5lcjb9G0v9IelXSyWrxLyStkXSZJk/j90u6tbqYV3ovjuxAzbo6je8Vwg7Uj/vGA8kRdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmh7w8ke+1DSu1Nen1stG0SD2tug9iXRW6d62dvftir09e/Zv7ZxezQiVjTWQMGg9jaofUn01ql+9cZpPJAEYQeSaDrsIw1vv2RQexvUviR661Rfemv0MzuA/mn6yA6gTwg7kEQjYbd9ne0/2R6zfWcTPbRie7/tV6tpqBudn66aQ2/C9t4pyxbafsb2m9XjtHPsNdTbQEzjXZhmvNF91/T0533/zG77LEl/lvRDSQckvSBpTUS81tdGWrC9X9KKiGj8Cxi2/17SMUn/cWpqLdsbJB2JiHur/1EuiIifD0hvd+sbTuNdU2+tphn/JzW473o5/XknmjiyXyFpLCLejojjkn4raWUDfQy8iHhW0pGvLF4paUv1fIsm/7H0XYveBkJEjEfEnur5J5JOTTPe6L4r9NUXTYT9Akl/mfL6gAZrvveQ9AfbL9oebrqZaQxNmWbrkKShJpuZRttpvPvpK9OMD8y+62T6825xge7rromIyyX9o6TbqtPVgRSTn8EGaez0V5K+q8k5AMclbWyymWqa8ccl/TQijk6tNbnvpumrL/utibAflLRkyuvF1bKBEBEHq8cJSU9q8mPHIDl8agbd6nGi4X7+X0QcjogvI+KkpE1qcN9V04w/Luk3EfFEtbjxfTddX/3ab02E/QVJy2x/x/ZsSaslbW+gj6+xPbe6cCLbcyX9SIM3FfV2Seuq5+skPdVgL39lUKbxbjXNuBred41Pfx4Rff+RdL0mr8i/JelfmuihRV8XSnq5+tnXdG+StmrytO6EJq9trJd0jqSdkt6U9N+SFg5Qb/+pyam9X9FksBY11Ns1mjxFf0XSS9XP9U3vu0JffdlvfF0WSIILdEAShB1IgrADSRB2IAnCDiRB2IEkCDuQxP8BiZUIHmh74tsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScIUfHpaQQyJ"
      },
      "source": [
        "def image_matrix(img):\n",
        "    print('\\n'.join([''.join(['{:4}'.format(int(round(item*255))) for item in row]) \n",
        "      for row in img]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6AK5fDJQQyM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58b96176-9f7c-437b-e6be-c4ffe89290b1"
      },
      "source": [
        "image_matrix(imagendemo)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0423305661014025   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   05023564770555901275   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   073956349564770647702295   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   011475647706477044370 510   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0102041820647706477021675   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   03723064770647706477021675   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0257556247564770647706477021675   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   024735632406477052020647706477021675   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   03060150452499038505604356477064770277958925647706477021675   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0104555508064770647706094539015943510208160647706477021675   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0178511220112207650   0   0   08160647706477024480   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   04845586506477044370   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0502356477028050   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0502356477021675   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0502356451516065   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   094351377013770114756630214205635521420535579054131019890   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   015301045535955622206477064770632406018064770647706477059415609456477035190   0   0   0   0   0   0\n",
            "   0   0   0   0   0   05865425856477064770647706477058395581404717535190351903519035190351903519011220   0   0   0   0   0   0\n",
            "   0   0   0   0   0   02881564770647706477045645163201275   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   08160532954666524735   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OONgVinO2Mj5"
      },
      "source": [
        "Preparando los datos para el entrenamiento\n",
        " \n",
        "La x debe ser convertida a un vector para que pueda ser procesada por la red perceptrón profunda \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssgZkgSJ2HIX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b290eb3-9dda-4f59-b411-3031a5b38c65"
      },
      "source": [
        "#Metemos la info tal y como queremos.\n",
        "#En tensorflow 1 ya venía el dato como vector (-,784) aquí en tensorflow2 la shape es (-,28,28) como imagen\n",
        "#-1 es para mantener el num de datos que se tiene, debemos colocar exactamente el tipo que queremos. Solo acepta ciertos tipos, si se quiere float es \n",
        "#float32, si queremos float64 hay que hacer modificaciones al código base\n",
        "x_train=x_train.reshape(-1,28*28).astype('float32')\n",
        "x_test=x_test.reshape(-1,28*28).astype('float32')\n",
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sniyszYT6wjg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6f7c70b-58f5-4d18-c107-190f220ddfd9"
      },
      "source": [
        "x_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIuVO17v31zI"
      },
      "source": [
        "Las salidas y deben se codificadas en one hot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ-cam6z4I-t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3f019f5-5dfc-4cf6-d4ff-2990e3636531"
      },
      "source": [
        "# onehot encode\n",
        "#no vienen one hot asi que debemos incorporarlo.\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "y_train = y_train.reshape(len(y_train), 1)\n",
        "y_train_onehot = onehot_encoder.fit_transform(y_train)\n",
        "\n",
        "y_test = y_test.reshape(len(y_test), 1)\n",
        "y_test_onehot = onehot_encoder.fit_transform(y_test)\n",
        "\n",
        "y_train_onehot.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUPvkJ1URpmy"
      },
      "source": [
        "### Declarando la arquitectura\n",
        "\n",
        "Generando función "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Y2usE7in_2p"
      },
      "source": [
        "class DNN_model(object):\n",
        "  #Se va a correr una sola vez, se ejecuta cuando se genera este objeto/clase\n",
        "  def __init__(self,\n",
        "               n_nodes_hl1=500,\n",
        "               n_nodes_hl2=500,\n",
        "               n_nodes_hl3=500,\n",
        "               n_classes=10):\n",
        "    #Los pesos y los bias son propiedades de este objeto self. \n",
        "    #La inicializacion es con numpy arrays. Y debemos generar el tipo de dato. Float32 es el mejor para tensorflow2\n",
        "    self.h1LW = tf.Variable(np.random.rand(784, n_nodes_hl1),name=\"hl1weigths\",dtype=\"float32\")\n",
        "    self.h1LB = tf.Variable(np.random.rand(n_nodes_hl1),name=\"hl1bias\",dtype=\"float32\")\n",
        "    self.h2LW = tf.Variable(np.random.rand(n_nodes_hl1, n_nodes_hl2),name=\"hl2weigths\",dtype=\"float32\")\n",
        "    self.h2LB = tf.Variable(np.random.rand(n_nodes_hl2),name=\"hl2bias\",dtype=\"float32\")\n",
        "    self.h3LW = tf.Variable(np.random.rand(n_nodes_hl2, n_nodes_hl3),name=\"hl3weigths\",dtype=\"float32\")\n",
        "    self.h3LB = tf.Variable(np.random.rand(n_nodes_hl3),name=\"hl3bias\",dtype=\"float32\")\n",
        "    self.outW = tf.Variable(np.random.rand(n_nodes_hl3, n_classes),name=\"outweigths\",dtype=\"float32\")\n",
        "    self.outB = tf.Variable(np.random.rand(n_classes),name=\"outbias\",dtype=\"float32\")\n",
        "    #Generamos etiqueta para poderlas llamar\n",
        "    self.trainable_variables =[self.h1LW,self.h1LB,self.h2LW,self.h2LB,self.h3LW,self.h3LB,self.outW,self.outB]   \n",
        "    #Propagación hacia adelante       \n",
        "  def __call__(self,x): \n",
        "      # Declarando la arquitectura\n",
        "\n",
        "      l1 = tf.add(tf.matmul(x,self.h1LW), self.h1LB)\n",
        "      l1 = tf.nn.relu(l1)\n",
        "\n",
        "      l2 = tf.add(tf.matmul(l1,self.h2LW), self.h2LB)\n",
        "      l2 = tf.nn.relu(l2)\n",
        "\n",
        "      l3 = tf.add(tf.matmul(l2,self.h3LW), self.h3LB)\n",
        "      l3 = tf.nn.relu(l3)\n",
        "\n",
        "      output = tf.matmul(l3,self.outW) + self.outB\n",
        "      return output\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SB_ocuTDRpm2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c42b8847-f7fc-4a4d-ca61-91c2d75bd157"
      },
      "source": [
        "DNN = DNN_model()\n",
        "DNN(x_train[24:30])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(6, 10), dtype=float32, numpy=\n",
              "array([[1.69050456e+11, 1.76245277e+11, 1.69957589e+11, 1.67389266e+11,\n",
              "        1.68017789e+11, 1.69469608e+11, 1.72368495e+11, 1.67053558e+11,\n",
              "        1.73378568e+11, 1.68369439e+11],\n",
              "       [3.12698733e+11, 3.26007325e+11, 3.14376126e+11, 3.09625553e+11,\n",
              "        3.10788391e+11, 3.13474384e+11, 3.18836179e+11, 3.09005353e+11,\n",
              "        3.20705135e+11, 3.11439426e+11],\n",
              "       [1.04094220e+11, 1.08524462e+11, 1.04652546e+11, 1.03071121e+11,\n",
              "        1.03458071e+11, 1.04352244e+11, 1.06137182e+11, 1.02864462e+11,\n",
              "        1.06759553e+11, 1.03674986e+11],\n",
              "       [3.53303921e+11, 3.68340337e+11, 3.55199058e+11, 3.49831430e+11,\n",
              "        3.51145132e+11, 3.54179809e+11, 3.60238121e+11, 3.49130424e+11,\n",
              "        3.62349462e+11, 3.51880380e+11],\n",
              "       [3.20471368e+11, 3.34110327e+11, 3.22190541e+11, 3.17321904e+11,\n",
              "        3.18513316e+11, 3.21266450e+11, 3.26761316e+11, 3.16686238e+11,\n",
              "        3.28676671e+11, 3.19180472e+11],\n",
              "       [1.20592417e+11, 1.25724877e+11, 1.21239536e+11, 1.19407395e+11,\n",
              "        1.19855751e+11, 1.20891654e+11, 1.22959315e+11, 1.19168188e+11,\n",
              "        1.23680211e+11, 1.20106705e+11]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOibydeqEJem"
      },
      "source": [
        "Seleccionar un optimizador "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1on8R5B5sLw"
      },
      "source": [
        "#optimizador = tf.keras.optimizers.Adam(learning_rate=0.001 )\n",
        "optimizador = tf.compat.v1.train.AdamOptimizer(learning_rate=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTAlRDeyAo_7"
      },
      "source": [
        "### Definir las metricas a usar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrMfhkpuAug4"
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnND6eokQQyb"
      },
      "source": [
        "### Calculo de gradientes y ajuste "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTTZsKgM_5U3"
      },
      "source": [
        "@tf.function\n",
        "def train_step(model,tdata, labels):\n",
        "  #Guarda los gradientes en variable tape. Le llaman cinta de gradiente. \n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(tdata)\n",
        "    #calculo de una funcion de error \n",
        "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels, predictions))\n",
        "   \n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  capped_grads_and_vars = [(grad,model.trainable_variables[index]) for index, grad in enumerate(gradients)]\n",
        "  optimizador.apply_gradients(capped_grads_and_vars)\n",
        "  train_loss(loss)\n",
        "  train_accuracy(labels, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZC1YbJ1D01G"
      },
      "source": [
        "#train_step(DNN,x_train[24:30], y_train_onehot[24:30])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97g8_iaQPtUk"
      },
      "source": [
        "@tf.function\n",
        "def test_step(model,tdata, labels):\n",
        "  predictions = model(tdata)\n",
        "  t_loss =  tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels, predictions))\n",
        "\n",
        "  test_loss(t_loss)\n",
        "  test_accuracy(labels, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lhnGNHMP6Kq"
      },
      "source": [
        "#test_step(DNN,x_train[24:30], y_train_onehot[24:30])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXi8dwZEN4fe"
      },
      "source": [
        "## función de entrenamiento  y prueba"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKZfZ5G4BKlp"
      },
      "source": [
        "\n",
        "def fitting(model,train_x,train_y,test_x,test_y,EPOCHS,N_batch,batch_size):\n",
        "  for epoch in range(EPOCHS):\n",
        "    i=0\n",
        "    while i+batch_size < len(train_x) or i+batch_size<batch_size*N_batch:\n",
        "      start = i\n",
        "      end = i+batch_size\n",
        "      batch_x = train_x[start:end]\n",
        "      batch_y = train_y[start:end]\n",
        "      train_step(model,batch_x,batch_y)\n",
        "      i+=batch_size\n",
        "\n",
        "    test_step(model,test_x,test_y)\n",
        "      \n",
        "    template = 'Epoch {}, Perdida: {}, Exactitud: {}, Perdida de prueba: {}, Exactitud de prueba: {}'\n",
        "    print(template.format(epoch+1,\n",
        "                         train_loss.result(),\n",
        "                        train_accuracy.result()*100,\n",
        "                        test_loss.result(),\n",
        "                        test_accuracy.result()*100))\n",
        "    #Borramos las variables para que no se acumulen\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "    test_loss.reset_states()\n",
        "    test_accuracy.reset_states()\n",
        "\n",
        "  \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFKfo19DRpnB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "434efbd1-a561-472e-e759-b1265914b983"
      },
      "source": [
        "fitting(DNN,x_train,y_train_onehot,x_test,y_test_onehot,10,600,100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Perdida: 300284160.0, Exactitud: 10.105175971984863, Perdida de prueba: 90102752.0, Exactitud de prueba: 10.100000381469727\n",
            "Epoch 2, Perdida: 66976980.0, Exactitud: 10.707846641540527, Perdida de prueba: 37545652.0, Exactitud de prueba: 10.279999732971191\n",
            "Epoch 3, Perdida: 9039424.0, Exactitud: 29.560935974121094, Perdida de prueba: 467970.75, Exactitud de prueba: 63.12999725341797\n",
            "Epoch 4, Perdida: 692607.25, Exactitud: 61.9432373046875, Perdida de prueba: 747027.5, Exactitud de prueba: 66.25999450683594\n",
            "Epoch 5, Perdida: 342919.90625, Exactitud: 71.00668334960938, Perdida de prueba: 278122.40625, Exactitud de prueba: 72.16999816894531\n",
            "Epoch 6, Perdida: 211419.984375, Exactitud: 77.0250473022461, Perdida de prueba: 227985.234375, Exactitud de prueba: 76.16000366210938\n",
            "Epoch 7, Perdida: 152342.953125, Exactitud: 80.98998260498047, Perdida de prueba: 143060.40625, Exactitud de prueba: 80.76000213623047\n",
            "Epoch 8, Perdida: 101020.09375, Exactitud: 84.13522338867188, Perdida de prueba: 50782.74609375, Exactitud de prueba: 89.9800033569336\n",
            "Epoch 9, Perdida: 62482.63671875, Exactitud: 86.5659408569336, Perdida de prueba: 81069.3984375, Exactitud de prueba: 82.18000030517578\n",
            "Epoch 10, Perdida: 38228.34375, Exactitud: 88.23371887207031, Perdida de prueba: 22179.8984375, Exactitud de prueba: 90.06999969482422\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}